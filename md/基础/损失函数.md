<!--
 * @Author: matiastang
 * @Date: 2021-12-15 14:24:02
 * @LastEditors: matiastang
 * @LastEditTime: 2021-12-15 15:44:12
 * @FilePath: /matias-AI/md/基础/损失函数.md
 * @Description: 
-->
* 损失函数为我们提供了计算损失的方法；
* 梯度下降是在损失函数基础上向着损失最小的点靠近而指引了网络权重调整的方向；
* 反向传播把损失值反向传给神经网络的每一层，让每一层都根据损失值反向调整权重；

Gold Standard Loss，又称0-1误差
loss=\begin{cases} 0 & a=y \\\\ 1 & a \ne y \end{cases}
loss= 
⎩
⎨
⎧
​	
  
0
1
​	
  
a=y
a

=y
​	
 

绝对值损失函数

loss = |y-a|
loss=∣y−a∣

Hinge Loss，铰链/折页损失函数或最大边界损失函数，主要用于SVM（支持向量机）中
loss=\max(0,1-y \cdot a) \qquad y=\pm 1
loss=max(0,1−y⋅a)y=±1

Log Loss，对数损失函数，又叫交叉熵损失函数(cross entropy error)
loss = -[y \cdot \ln (a) + (1-y) \cdot \ln (1-a)] \qquad y \in \\{ 0,1 \\}
loss=−[y⋅ln(a)+(1−y)⋅ln(1−a)]y∈
0,1

Squared Loss，均方差损失函数
loss=(a-y)^2
loss=(a−y) 
2
 

Exponential Loss，指数损失函数
loss = e^{-(y \cdot a)}
loss=e 
−(y⋅a)