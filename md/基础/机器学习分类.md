<!--
 * @Author: matiastang
 * @Date: 2022-08-04 09:44:09
 * @LastEditors: matiastang
 * @LastEditTime: 2022-08-04 10:56:38
 * @FilePath: /matias-AI/md/基础/机器学习分类.md
 * @Description: 机器学习（ML）
-->
# 机器学习（ML）

![人工智能](../images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD.png)

**机器学习是通过编程让计算机从数据中进行学习的科学（和艺术）**

原因如下：

* 需要进行大量手工调整或需要拥有长串规则才能解决的问题：机器学习算法通常可以简化代码、提高性能。
* 问题复杂，传统方法难以解决：最好的机器学习方法可以找到解决方案。
* 环境有波动：机器学习算法可以适应新数据。
* 洞察复杂问题和大量数据

一些机器学习的应用例子：

* 数据挖掘
* 一些无法通过手动编程来编写的应用：如自然语言处理，计算机视觉、语音识别等
* 一些自助式的程序：如推荐系统等
* 理解人类是如何学习的

## 机器学习分类

机器学习根据不同规则分类不同：

* 是否在人类监督下进行训练（`监督`，`非监督`，`半监督`和`强化学习`）
* 是否可以动态渐进学习（`在线学习` vs `批量学习`）
* 它们是否只是通过简单地比较新的数据点和已知的数据点，或者在训练数据中进行模式识别，以建立一个预测模型，就像科学家所做的那样（`基于实例学习` vs `基于模型学习`）

### 监督学习

监督学习，顾名思义就是带有监督的学习，而监督就是体现在训练数据都是`有标签`的，所有在训练模型的时候可以根据数据的`真实标签`不断调整模型，从而得到一个性能更好的模型。

监督学习主要有两个常见的典型的任务--`分类`和`回归`。

常用的监督学习算法有：

* `K近邻算法`
* `线性回归`
* `逻辑回归`
* `支持向量机（SVM）`
* `决策树和随机森林`
* `神经网络`

#### 分类

#### 回归

### 非监督学习

和监督学习相反，非监督学习就是采用`没有标签`的数据集。

非监督主要有四个典型的任务，分别是`聚类`、`降维`、`异常检测`和`关联规则学习`。

非监督学习算法：

1. 聚类`

* `K 均值`
* `层次聚类分析（Hierarchical Cluster Analysis, HCA）`
* `期望最大值`



2. 可视化和降维

* `主成分分析（Principal Component Analysis, PCA）`
* `核主成分分析`
* `局部线性嵌入（Locally-Linear Embedding, LLE）`
* `t-分布邻域嵌入算法（t-distributed Stochastic Neighbor Embedding, t-SNE）`

3. 关联性规则学习

* `Apriori 算法`
* `Eclat算法`

#### 聚类

`聚类`就是将数据根据`一定的规则`分成多个类，通常是采用相似性。比如对于博客访客的聚类，通过聚类算法，检测相似性访客的分组。
`可视化算法`也是极佳的非监督学习案例：**给算法大量复杂的且不加标签的数据，算法输出数据的2D或3D图像**。

#### 降维

`降维`的目的是简化数据、但是不能失去大部分信息。做法之一是合并若干相关的特征。例如，汽车的里程数与车龄高度相关，降维算法就会将它们合并成一个，表示汽车的磨损。这叫做特征提取。

此外，在采用机器学习算法训练的时候，可以对训练集进行降维，这样有助于提高训练速度，降低占用的硬盘和内存空间，有时候也能提高算法的性能，但必须选择合适的降维算法，否则性能实际上是很有可能会下降的。

让我想到了`CNN`

#### 异常检测

另一个重要的非监督任务是`异常检测（anomaly detection）`。例如，检测异常的信用卡转账以防欺诈，检测制造缺陷，或者在训练之前自动从训练数据集去除异常值。异常检测的系统使用正常值训练的，当它碰到一个新实例，它可以判断这个新实例是像正常值还是异常值。

#### 关联规则学习

另一个常见的非监督任务是关联规则学习，它的目标是挖掘大量数据以发现属性间有趣的关系。例如，假设你拥有一个超市。在销售日志上运行关联规则，可能发现买了烧烤酱和薯片的人也会买牛排。因此，你可以将这些商品放在一起。

### 半监督学习

一些算法可以处理部分带标签的训练数据，通常是大量`不带标签数据`加上小部分`带标签数据`。这称作`半监督学习`。

**多数半监督学习算法是非监督和监督算法的结合**。例如，深度信念网络（deep belief networks）是基于被称为互相叠加的受限玻尔兹曼机（restricted Boltzmann machines，RBM）的非监督组件。RBM 是先用非监督方法进行训练，再用监督学习方法进行整个系统微调。

半监督学习的示例，如一些图片存储服务，比如 Google Photos，是半监督学习的好例子。一旦你上传了所有家庭相片，它就能自动识别相同的人 A 出现了相片1、5、11 中，另一个人 B 出现在了相片 2、5、7 中。这是算法的非监督部分（聚类）。现在系统需要的就是你告诉这两个人是谁。只要给每个人一个标签，算法就可以命名每张照片中的每个人，特别适合搜索照片。

### 强化学习

`强化学习`和上述三种学习问题是非常不同的。学习系统在这里被称为`智能体（ agent）`，可以对环境进行观察，选择和执行动作，获得奖励（负奖励是惩罚，见下图）。然后它必须自己学习哪个是最佳方法（称为策略，policy），以得到长久的最大奖励。策略决定了智能体在给定情况下应该采取的行动 。

目前强化学习的应用还不算非常广，特别是结合了`深度学习`的`强化学习`，主要是应用在机器人方面，当然最著名的一个应用就是 `DeepMind` 的 `AlphaGo` 了，它是通过分析数百万盘棋局学习制胜策略，然后自己和自己下棋。要注意，在比赛中机器学习是关闭的；`AlphaGo` 只是使用它学会的策略。

### 批量和在线学习

是否能从导入的数据流进行持续学习。也就是如果导入的是持续的数据流，机器学习算法能否在不断采用新数据来训练已经训练好的模型，并且新的模型对新旧数据都还有很好的性能。

#### 批量学习

在批量学习中，**系统不能进行持续学习：必须用所有可用数据进行训练**。这通常会占用大量时间和计算资源，所以一般是线下做的。首先是进行训练，然后部署在生产环境且停止学习，它只是使用已经学到的策略。这称为离线学习。

对于批量学习算法来说，当获取到新数据的时候，就需要重新重头训练整个数据集，然后更新模型，如果是应用该算法系统，那就相当于需要更新系统，需要停掉旧版本的系统，重新上线新版本的系统。

当然，一般训练、评估、部署一套机器学习的系统的整个过程可以自动进行，所以即便是批量学习也可以适应改变。只要有需要，就可以方便地更新数据、训练一个新版本。并且对于更新周期，可以选择每 24 小时或者每周更新一次。

但是，批量学习还是存在下面的缺点：

* 实时性差，即对于需要快速适应变化的系统，比如预测股票变化、电商推荐系统等，就不适合采用批量学习算法；
* 耗费大量计算资源，用全部数据训练需要大量计算资源（CPU、内存空间、磁盘空间、磁盘 I/O、网络 I/O 等等），特别是训练集特别大的情况，更加凸显这个问题的严峻性；
* 无法应用在资源有限的设备上，比如需要自动学习的系统，但是如果采用智能手机，每次采用大量训练数据重新训练几个小时是非常不实际的。

#### 在线学习

批量学习的缺陷和问题可以通过采用在线学习算法来解决。

在在线学习中，是用数据实例持续地进行训练，可以一次一个或一次几个实例（称为小批量）。每个学习步骤都很快且廉价，所以系统可以动态地学习到达的新数据。

在线学习虽然名字带着在线两个字，但是实际上它的训练过程也是离线的，因此应该说是`持续学习`或者`增量学习`。

在线学习有下面几个优点：

* 实时性好。在线学习算法非常适合接收连续流的数据，然后自动更新模型，实时性比批量学习更好；
* 可以节省大量计算资源。在线学习算法在学习新数据后，可以扔掉训练数据，从而节省大量存储空间；此外，训练得过程不需要加载所有训练数据，对于内存、CPU 等资源的要求也大大减少；
* 实现核外学习(out-of-core learning)。当内存不足以加载训练集的时候，可以采用在线学习算法多次训练，每次加载一部分训练集，即将一部分训练集当做新数据不断加载，直到训练完所有数据。

在线学习也存在两个挑战：

* 学习速率问题。学习速率是在线学习的一个重要参数，它反映了在线学习算法有多快地适应数据的改变，必须选择一个合适的学习速率，因为学习速率过大，系统可以很快适应新数据，但是也容易遗忘旧数据，比如图像分类问题，训练了一个 50 类分类器后，增加新的 10 类数据，一旦学习速率过快，系统只会记住新的 10 个类别，忘记了前面的 50 个类别的数据。相反的，如果你设定的学习速率低，系统的惰性就会强：即，它学的更慢，但对新数据中的噪声或没有代表性的数据点结果不那么敏感。
* 坏数据的影响。如果采用坏数据训练，会破坏系统的性能。要减小这种风险，你需要密集监测，如果检测到性能下降，要快速关闭（或是滚回到一个之前的状态）。你可能还要监测输入数据，对反常数据做出反应（比如，使用异常检测算法）。

### 基于实例 vs 基于模型学习

第三种分类机器学习的方法是判断它们是如何进行归纳推广的。大多机器学习任务是关于预测的。这意味着给定一定数量的训练样本，系统需要能推广到之前没见到过的样本。对训练数据集有很好的性能还不够，真正的目标是对新实例预测的性能。

有两种主要的归纳方法：`基于实例学习`和`基于模型学习`。

#### 基于实例

基于实例学习是**系统先用记忆学习案例，然后使用相似度测量推广到新的例子**

这种学习算法可以说是机器学习中最简单的算法了，它实际上就是采用存储的数据集进行分类或者回归，典型的算法就是 `KNN 算法，即 K 近邻算法`，`它就是将新的输入数据和已经保存的训练数据采用相似性度量（一般采用欧式距离）得到最近的 K 个训练样本，并采用 K 个训练样本中类别出现次数最多的类别作为预测的结果`。

所以，这种算法的缺点就比较明显了：

* 一是对存储空间的需求很大，需要占用的空间直接取决于实例数量的大小；
* 二是运行时间比较慢，因为需要需要与已知的实例进行比对。

#### 基于模型学习

和基于实例学习相反的就是基于模型学习：**建立这些样本的模型，然后使用这个模型进行预测**。

基于模型学习算法的流程一般如下所示：

* `研究数据`。先对数据进行分析，这可能包含`清洗数据`、`特征筛选`、`特征组合`等等
* `选择模型`。选择合适的模型，从简单的`线性回归`、`逻辑回归`，到慢慢复杂的`随机森林`、`集成学习`，甚至`深度学习的卷积神经网络模型`等等
* 用训练数据进行`训练`。也就是寻找最适合算法模型的参数，使得代价函数取得最小值。
* 使用模型对新案例进行`预测`（这称作推断）。预测结果非常好，就能上线系统；如果不好，就需要进行错误分析，问题出现在哪里，是数据问题还是模型问题，找到问题，然后继续重复这个流程。

## 问题

### 数据问题

#### 训练数据量不足
#### 没有代表性的训练数据
#### 低质量的数据
#### 不相关的特征

### 算法问题

#### 过拟合

过拟合就是指算法模型在`训练集上的性能非常好`，但是`泛化能力很差`，即在测试集上的效果却很糟糕的情况。

通常对于比较复杂的模型，比如深度神经网络，它能够检测和识别到数据中比较细微的规律和特征，但是如果`训练集包含噪声`，或者`训练集数量太少（数量太少会引入样本噪声）`，这种情况下，模型同样会学习这种噪声，从而导致模型的`泛化能力`的下降。

一般解决过拟合的方法有：

* 简化模型，这包括了采用简单点的模型、减少特征数量以及`限制模型`，即采用`正则化`；
* 增加训练数据
* 减小训练数据的`噪声`，即`数据清洗`，比如`修正数据错误`和`去除异常值`等

其中正则化方法是比较常用的方法，它的作用就是限制模型，不让模型过于复杂，从而降低过拟合的风险或者是缓和过拟合的程度。常用的正则化方法是 L2 和 L1 正则化。正则化方法通常会采用一个超参数来控制其限制模型的强度。超参数是一个学习算法的参数（而不是模型的）。这样，它是不会被学习算法本身影响的，它优于训练，在训练中是保持不变的。如何调节超参数也是构建一个机器学习算法模型非常重要的一个步骤，也是让性能能够进一步提升的做法。

#### 欠拟合

欠拟合和过拟合刚好相反，它就是`模型的性能非常差，在训练数据和测试数据上的性能都不好`。

通常也是因为`模型过于简单，没有能够很好学习到数据的有效的相关的特征`，解决方法有：

* 选择一个更强大的模型，带有更多参数
* 用更好的特征训练学习算法（特征工程）
* 减小对模型的限制（比如，`减小正则化超参数`）

## 测试验证

当训练好一个机器学习模型后，接下来就需要对模型进行预测和评估，判断得到的模型是否可用，是否还能进行提升，并进行错误分析等操作。

一般在训练模型前，我们会将数据集分成两个集合，分别是训练集和测试集，通常 8:2 的比例，也就是 `80% 的数据作为训练集`，`剩余是测试集`。然后采用训练集训练模型，在测试集上用按照学习的问题采用对应评估指标评估模型的性能，比如分类问题，一般就是采用分类的准确率或者错误率作为评估的标准。

但这种划分数据集的方法，存在一个问题，**就是如果需要调节超参数，比如对于`正则化`的超参数、`学习率`等，继续采用测试集来进行评估不同超参数对模型性能的影响，这会导致最后在测试集上测试得到性能最好的模型，实际上是过拟合了测试集，那么模型的泛化能力也不会太好**。

所以，为了解决这个问题，我们还需要为调节超参数划分一个专门的数据集，测试集应该是用于测试最终得到的模型的性能。因此，我们再划分一个叫做验证集的数据集。

一种做法是可以将所有数据按照一定比例划分为**`训练集`、`验证集`和`测试集`，比如按照 6:2:2 的比例划分**；当然更通常的做法是采用交叉验证：训练集分成互补的子集，每个模型用不同的子集训练，再用剩下的子集验证。一旦确定模型类型和超参数，最终的模型使用这些超参数和全部的训练集进行训练，用测试集得到推广误差率。

## 总结

* 机器学习就是让机器通过学习数据得到解决更好解决某些问题的能力，而不需要确定的代码规则；
* 机器学习的应用非常广泛，包含图像、自然语言处理、语音、推荐系统和搜索等方面，每个方面还有更加具体详细的应用方向；
* 机器学习按照不同的划分标准可以分为不同的学习类型，包括监督和非监督学习、批量和在线学习，基于实例和基于模型学习；
* 最常见的监督学习任务是分类和回归；
* 常见的非监督学习任务是聚类、降维、异常值检测和关联规则学习；

机器学习的四个主要挑战是

* 数据量太少
* 数据问题，包括没有代表性数据和质量差
* 不相关特征
* 模型过拟合或者欠拟合

1. 过拟合的解法方法有：

* 简化模型，包括采用更简单的模型和更少的参数
* 正则化方法降低模型的复杂度
* 收集或者采用更大的数据集
* 数据清洗，去除噪声和异常值等

3. 欠拟合的解决方法：

* 采用更强大的模型，包含更多的参数和学习能力
* 降低正则化的强度
* 使用更好的特征提取方法，即使用或者改善特征工程的工作

4. 采用交叉验证方法进行超参数条件和模型的选择

