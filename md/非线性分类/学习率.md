<!--
 * @Author: matiastang
 * @Date: 2022-08-08 14:52:34
 * @LastEditors: matiastang
 * @LastEditTime: 2022-08-08 14:52:37
 * @FilePath: /matias-AI/md/非线性分类/学习率.md
 * @Description: 学习率
-->
# 学习率

fixed⚓︎
使用固定的学习率，比如全程都用0.1。要注意的是，这个值不能大，否则在后期接近极值点时不易收敛。

step⚓︎
每迭代一个预订的次数后（比如500步），就调低一次学习率。离散型，简单实用。

multistep⚓︎
预设几个迭代次数，到达后调低学习率。与step不同的是，这里的次数可以是不均匀的，比如3000、5500、8000。离散型，简单实用。

exp⚓︎
连续的指数变化的学习率，公式为：

 
由于一般的iteration都很大（训练需要很多次迭代），所以学习率衰减得很快。可以取值0.9、0.99等接近于1的数值，数值越大，学习率的衰减越慢。

inv⚓︎
倒数型变化，公式为：

 
 
控制下降速率，取值越大下降速率越快；控制最小极限值，取值越大时最小值越小，可以用0.5来做缺省值。

poly⚓︎
多项式衰减，公式为：

 
 
时，为线性下降；时，下降趋势向上突起；时，下降趋势向下凹陷。可以设置为0.9。