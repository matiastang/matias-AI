<!--
 * @Author: matiastang
 * @Date: 2022-08-08 15:39:56
 * @LastEditors: matiastang
 * @LastEditTime: 2022-08-08 15:46:19
 * @FilePath: /matias-AI/md/DNN/正则化.md
 * @Description: 正则化
-->
# 正则化

正则化的英文为Regularization，用于防止过拟合。

出现过拟合的原因：

* 训练集的数量和模型的复杂度不匹配，样本数量级小于模型的参数
* 训练集和测试集的特征分布不一致
* 样本噪音大，使得神经网络学习到了噪音，正常样本的行为被抑制
* 迭代次数过多，过分拟合了训练数据，包括噪音部分和一些非重要特征

既然模型过于复杂，那么我们简化模型不就行了吗？为什么要用复杂度不匹配的模型呢？有两个原因：

1. 因为有的模型以及非常成熟了，比如VGG16，可以不调参而直接用于你自己的数据训练，此时如果你的数据数量不够多，但是又想使用现有模型，就需要给模型加正则项了。
2. 使用相对复杂的模型，可以比较快速地使得网络训练收敛，以节省时间。

解决过拟合问题⚓︎
有了直观感受和理论知识，下面我们看看如何解决过拟合问题：

* 数据扩展
* 正则
* 丢弃法
* 早停法
* 集成学习法
* 特征工程（属于传统机器学习范畴，不在此处讨论）
* 简化模型，减小网络的宽度和深度