<!--
 * @Author: matiastang
 * @Date: 2022-08-08 16:00:22
 * @LastEditors: matiastang
 * @LastEditTime: 2022-08-08 16:00:25
 * @FilePath: /matias-AI/md/DNN/丢弃法.md
 * @Description: 丢弃法
-->
# 丢弃法

Dropout可以作为训练深度神经网络的一种正则方法供选择。在每个训练批次中，通过忽略一部分的神经元（让其隐层节点值为0），可以明显地减少过拟合现象。这种方式可以减少隐层节点间的相互作用，高层的神经元需要低层的神经元的输出才能发挥作用，如果高层神经元过分依赖某个低层神经元，就会有过拟合发生。在一次正向/反向的过程中，通过随机丢弃一些神经元，迫使高层神经元和其它的一些低层神经元协同工作，可以有效地防止神经元因为接收到过多的同类型参数而陷入过拟合的状态，来提高泛化程度。

